import os
import torch
from torch import nn
import pandas as pd
from tqdm import tqdm
import numpy as np
from models import CrazyThursdayKFC
from train import BertConfig
from support_function import  Norm_CorrelationFunction, Origin_CorrelationFunction
from matplotlib import pyplot as plt
from support_Loss import Cl_Loss, MSE_Loss
from support_deal import load_data, preprocess, data_filter, minmax_norm, minmax_denorm
from support_models import generate_fake_sample
from sklearn.metrics import mean_squared_error
import time


if __name__ == "__main__":

    # model_path = r"D:\Zang\deeplearn_temp\model_Z_1125_cl.pkl"
    # model_path = r"C:\Users\lonel\OneDrive\软件\DeepLearn\general_dl\model_en.pkl"
    model_path = r"D:\Zang\deeplearn_temp\model_float.pkl"
    # data_path = r"C:\Users\lonel\OneDrive\软件\DeepLearn\ACF验证数据\real_data\test_data\34.csv"
    # data_path = r"C:\Users\lonel\OneDrive\软件\DeepLearn\general_data\84.csv"

    bert_config = BertConfig()
    model = CrazyThursdayKFC(bert_config)
    # model.load_state_dict(torch.load(model_path, map_location='cpu'), strict=True)
    model.load_state_dict(torch.load(model_path, map_location='cuda'), strict=True)
    model = model.cuda()   
    model.eval()

    data, act_params = generate_fake_sample(1000, 0.3)
    data = torch.tensor(data).float().cuda()
    deal_data, norm_params, y_min = preprocess((data))
    
    def Params_denorm(params, norm_params):
    # params = torch.tensor(params)
        norm_params = norm_params.squeeze() 
        params[:,1] = params[:,1] * norm_params
        params[:,2] = torch.pow(10, (-1-4*params[:,2]))
        params[:,4] =torch.pow(10, (-5-4*params[:,4]))
        params[:,5] = (params[:,5] * 0.216) + 0.1
        
        return params

    with torch.no_grad():
        
        deal_data = torch.tensor(deal_data).float().cuda() 
        input_data = deal_data
        attention_mask = torch.zeros(input_data.shape[:-1]).cuda()
        # The six parameters predicted by the model.
        start_time = time.time()
        outputs_params = model(input_data, attention_mask)
        end_time = time.time()
        real_params = Params_denorm(outputs_params, norm_params)
        # The y-sequence generated by the function with the six parameters above.
        all_y_primes = []
        for i in range(real_params.shape[0]):
            y_prime = (Origin_CorrelationFunction(input_data[:, :, 0][i], *real_params[i])-1)/norm_params[i]
            y_prime_cpu = y_prime.cpu().numpy()
            all_y_primes.append(y_prime_cpu) 

        # y_pre_pred, y_min, y_max = np.y_pre_pred, np.y_min, np.y_max
    all_y_primes = np.array(all_y_primes)
    deal_data = deal_data.cpu().numpy()
    total_y_mse = mean_squared_error(deal_data[:, :, 1], all_y_primes)

    real_params = real_params.cpu().numpy()
    c, N, Td, T, Tt, s, f = real_params.T
    # print(f'N: {N}, Td: {Td}, T: {T}, Tt: {Tt}, s: {s}, f: {f}')
    all_params_mse = mean_squared_error(real_params, act_params)

    mse_per_param = {}
    param_names = ['c', 'N', 'Td', 'T', 'Tt', 's', 'f']
    for idx, name in enumerate(param_names):
        mse_per_param[name] = mean_squared_error(real_params[:, idx], act_params[:, idx])

    fitting_time = end_time - start_time
    # 输出结果
    print(f"data: {total_y_mse}")
    print(f"params_mse: {all_params_mse}")
    print(f"fitting time: {fitting_time}")
    for param, mse in mse_per_param.items():
        print(f"MSE for {param}: {mse}")

        
